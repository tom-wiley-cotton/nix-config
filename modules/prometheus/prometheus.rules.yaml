groups:
- name: alerts
  rules:
  - alert: HostDown
    expr: up{job="node"} == 0
    for: 15m
    labels:
      severity: critical
    annotations:
      description: '{{ $labels.instance }} is down for more than 15 minutes'
  - alert: HostSystemdServiceCrashed
    expr: (node_systemd_unit_state{state="failed",name!="systemd-networkd-wait-online.service"} == 1) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    labels:
      severity: warning
    annotations:
      description: "Service {{ $labels.name }} crashed"
  - alert: HostRaidDiskFailure
    expr: (node_md_disks{state="failed"} > 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    for: 2m
    labels:
      severity: error
    annotations:
      description: "At least one device in RAID array on {{ $labels.instance }} failed. Array {{ $labels.md_device }} needs attention and possibly a disk swap."
  - alert: HostOomKillDetected
    expr: (increase(node_vmstat_oom_kill[1m]) > 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    labels:
      severity: warning
    annotations:
      description: "OOM kill detected"
  # - alert: HostNetworkPacketDropEgress
  #   expr: rate(node_network_transmit_drop_total{device!="flannel.1"}[2m]) > 0
  #   for: 5m
  #   labels:
  #     severity: warning
  #   annotations:
  #     description: '{{ $labels.instance }} drops packages for more than 5 minutes'
  # - alert: HostNetworkPacketDropIngress
  #   expr: rate(node_network_receive_drop_total[2m]) > 0.5
  #   for: 5m
  #   labels:
  #     severity: warning
  #   annotations:
  #     description: '{{ $labels.instance }} drops packages for more than 5 minutes'
  - alert: HostNetworkBondDegraded
    expr: ((node_bonding_active - node_bonding_slaves) != 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "Bond {{ $labels.device }} degraded on {{ $labels.instance }}."
  - alert: HostNetworkInterfaceSaturated
    expr: ((rate(node_network_receive_bytes_total{device!~"^tap.*|^vnet.*|^veth.*|^tun.*"}[1m]) + rate(node_network_transmit_bytes_total{device!~"^tap.*|^vnet.*|^veth.*|^tun.*"}[1m])) / node_network_speed_bytes{device!~"^tap.*|^vnet.*|^veth.*|^tun.*"} > 0.8 < 10000) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    for: 1m
    labels:
      severity: warning
    annotations:
      description: "The network interface {{ $labels.device }} on {{ $labels.instance }} is getting overloaded."
  - alert: HostNetworkReceiveErrors
    expr: (rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "Host {{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf \"%.0f\" $value }} receive errors in the last two minutes."
  - alert: HostNetworkTransmitErrors
    expr: (rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m]) > 0.01) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "Host {{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf \"%.0f\" $value }} transmit errors in the last two minutes."
  - alert: BlackboxProbeFailed
    for: 15m
    expr: probe_success == 0
    labels:
      severity: critical
    annotations:
      description: "Probe failed"

  - alert: ZfsPoolDegraded
    expr: zfs_pool_health > 0
    for: 2m
    labels:
      severity: critical
    annotations:
      description: 'ZFS pool {{ $labels.pool }} on {{ $labels.instance }} is degraded. State: {{ $value }}'

  - alert: ZfsPoolHighUsage
    expr: (zfs_pool_allocated_bytes / (zfs_pool_allocated_bytes + zfs_pool_free_bytes)) * 100 > 80
    for: 10m
    labels:
      severity: warning
    annotations:
      description: 'ZFS pool {{ $labels.pool }} on {{ $labels.instance }} is at {{ printf "%.1f" $value }}% capacity'

  - alert: ZfsPoolCriticalUsage
    expr: (zfs_pool_allocated_bytes / (zfs_pool_allocated_bytes + zfs_pool_free_bytes)) * 100 > 90
    for: 10m
    labels:
      severity: critical
    annotations:
      description: 'ZFS pool {{ $labels.pool }} on {{ $labels.instance }} is critically full at {{ printf "%.1f" $value }}% capacity'

  - alert: ZfsPoolFragmentation
    expr: zfs_pool_fragmentation_ratio > 0.5
    for: 30m
    labels:
      severity: warning
    annotations:
      description: 'ZFS pool {{ $labels.pool }} on {{ $labels.instance }} has high fragmentation ratio of {{ printf "%.2f" $value }}'

  - alert: ZfsPoolLeaked
    expr: zfs_pool_leaked_bytes > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      description: 'ZFS pool {{ $labels.pool }} on {{ $labels.instance }} has {{ printf "%.0f" $value }} bytes of leaked data'

  - alert: BleSensorOffline
    expr: homeassistant_sensor_unit_seconds{domain="sensor",entity="sensor.main_ble_sensor_age",instance="homeassistant:8123"} > 5000
    for: 5m
    labels:
      severity: critical
    annotations:
      description: 'BLE sensor {{ $labels.entity }} on {{ $labels.instance }} is not responding.'
  - alert: CondoBleSensorOffline
    expr: homeassistant_sensor_unit_seconds{domain="sensor",entity="sensor.main_ble_sensor_age",instance="condo-ha:8123"} > 5000
    for: 5m
    labels:
      severity: critical
    annotations:
      description: 'Condo BLE sensor {{ $labels.entity }} on {{ $labels.instance }} is not responding.'
  - alert: Main Temp too Low
    expr: sum(homeassistant_sensor_temperature_celsius{friendly_name="Main Temperature", instance="homeassistant:8123"}) - sum(homeassistant_climate_target_temperature_celsius{friendly_name="Main Thermostat", instance="homeassistant:8123"}) < -1
    for: 5m
    labels:
      severity: critical
    annotations:
      description: 'Main temp is colder than set point by {{ printf "%.0f" $value }}C. Cycle the hot water.'